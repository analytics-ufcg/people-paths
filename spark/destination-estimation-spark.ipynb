{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import lit, unix_timestamp, regexp_replace, hour, minute, floor, col\n",
    "\n",
    "import json\n",
    "#from pyspark.ml.feature import VectorAssembler\n",
    "#from pyspark.ml import Pipeline\n",
    "#from pyspark.ml.feature import StringIndexer\n",
    "#from pyspark.mllib.evaluation import RegressionMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rename_columns(df, list_of_tuples):\n",
    "    for (old_col, new_col) in list_of_tuples:\n",
    "        df = df.withColumnRenamed(old_col, new_col)\n",
    "\n",
    "    return df\n",
    "\n",
    "def read_file(filepath, sqlContext):\n",
    "    data_frame = sqlContext.read.format(\"com.databricks.spark.csv\") \\\n",
    "        .option(\"header\", \"false\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .option(\"nullValue\", \"-\") \\\n",
    "        .load(filepath)\n",
    "\n",
    "    while len(data_frame.columns) < 16:\n",
    "        col_name = \"_c\" + str(len(data_frame.columns))\n",
    "        data_frame = data_frame.withColumn(col_name, lit(None))\n",
    "\n",
    "    data_frame = rename_columns(\n",
    "        data_frame,\n",
    "        [\n",
    "            (\"_c0\", \"route\"),\n",
    "            (\"_c1\", \"tripNum\"),\n",
    "            (\"_c2\", \"shapeId\"),\n",
    "            (\"_c3\", \"shapeSequence\"),\n",
    "            (\"_c4\", \"shapeLat\"),\n",
    "            (\"_c5\", \"shapeLon\"),\n",
    "            (\"_c6\", \"distanceTraveledShape\"),\n",
    "            (\"_c7\", \"busCode\"),\n",
    "            (\"_c8\", \"gpsPointId\"),\n",
    "            (\"_c9\", \"gpsLat\"),\n",
    "            (\"_c10\", \"gpsLon\"),\n",
    "            (\"_c11\", \"distanceToShapePoint\"),\n",
    "            (\"_c12\", \"timestamp\"),\n",
    "            (\"_c13\", \"busStopId\"),\n",
    "            (\"_c14\", \"problem\"),\n",
    "            (\"_c15\", \"numPassengers\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    date = \"-\".join(filepath.split(\"/\")[-2].split(\"_\")[:3])\n",
    "\n",
    "    data_frame = data_frame.withColumn(\"date\", lit(date))\n",
    "\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Read Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()\n",
    "sqlContext = pyspark.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_data = read_file('/local/tarciso/data/sample-data/bulma-output/2017_05_11_veiculos.csv/part-00000', sqlContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(route=u'372', tripNum=4, shapeId=1891, shapeSequence=6136916, shapeLat=-25.432724990605614, shapeLon=-49.27218701780396, distanceTraveledShape=10149.88, busCode=u'CC170', gpsPointId=None, gpsLat=None, gpsLon=None, distanceToShapePoint=None, timestamp=u'12:13:43', busStopId=None, problem=u'BETWEEN', numPassengers=None, date=u'2017-05-11')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- route: string (nullable = true)\n",
      " |-- tripNum: integer (nullable = true)\n",
      " |-- shapeId: integer (nullable = true)\n",
      " |-- shapeSequence: integer (nullable = true)\n",
      " |-- shapeLat: double (nullable = true)\n",
      " |-- shapeLon: double (nullable = true)\n",
      " |-- distanceTraveledShape: double (nullable = true)\n",
      " |-- busCode: string (nullable = true)\n",
      " |-- gpsPointId: string (nullable = true)\n",
      " |-- gpsLat: double (nullable = true)\n",
      " |-- gpsLon: double (nullable = true)\n",
      " |-- distanceToShapePoint: double (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- busStopId: integer (nullable = true)\n",
      " |-- problem: string (nullable = true)\n",
      " |-- numPassengers: integer (nullable = true)\n",
      " |-- date: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-------+-------------+-------------------+-------------------+---------------------+-------+----------+----------+----------+--------------------+---------+---------+----------+-------------+----------+\n",
      "|route|tripNum|shapeId|shapeSequence|           shapeLat|           shapeLon|distanceTraveledShape|busCode|gpsPointId|    gpsLat|    gpsLon|distanceToShapePoint|timestamp|busStopId|   problem|numPassengers|      date|\n",
      "+-----+-------+-------+-------------+-------------------+-------------------+---------------------+-------+----------+----------+----------+--------------------+---------+---------+----------+-------------+----------+\n",
      "|  372|      4|   1891|      6136916|-25.432724990605614| -49.27218701780396|             10149.88|  CC170|      null|      null|      null|                null| 12:13:43|     null|   BETWEEN|         null|2017-05-11|\n",
      "|  372|      4|   1891|      6136915|-25.432470122014415| -49.27231020615159|            10119.046|  CC170|      null|      null|      null|                null| 12:45:14|     null|   BETWEEN|         null|2017-05-11|\n",
      "|  372|      1|   1891|      6136650|-25.413362156585787| -49.20592429766663|               79.983|  CC170|      null|-25.413378|-49.205836|            9.041484| 05:41:14|     null|NO_PROBLEM|         null|2017-05-11|\n",
      "|  372|      1|   1891|      6136651|-25.413482250291853| -49.20586900611687|               94.403|  CC170|      null|      null|      null|                null| 05:41:16|     null|   BETWEEN|         null|2017-05-11|\n",
      "|  372|      1|   1891|      6136652|-25.413648732588364| -49.20578819324544|              114.558|  CC170|      null|-25.413681| -49.20582|            4.804002| 05:41:20|     null|NO_PROBLEM|         null|2017-05-11|\n",
      "|  372|      1|   1891|      6136653|-25.413842469921647| -49.20568793435859|              138.272|  CC170|      null|-25.413863|-49.205595|            9.608952| 05:41:27|     null|NO_PROBLEM|         null|2017-05-11|\n",
      "|  372|      1|   1891|      6136654|-25.413724525004074| -49.20539007960065|              170.964|  CC170|      null|-25.413713|-49.205263|             12.8274| 05:41:31|     null|NO_PROBLEM|         null|2017-05-11|\n",
      "|  372|      1|   1891|      6136655|-25.413590832789257|-49.205053332811985|               207.94|  CC170|      null|      null|      null|                null| 05:41:33|     null|   BETWEEN|         null|2017-05-11|\n",
      "|  372|      1|   1891|      6136656|-25.413418537980533| -49.20460983865769|              256.471|  CC170|      null|-25.413501|-49.204675|            11.26532| 05:41:37|     null|NO_PROBLEM|         null|2017-05-11|\n",
      "|  372|      1|   1891|      6136657| -25.41329245665092|-49.204275993402746|              292.847|  CC170|      null| -25.41329|-49.204133|           14.364174| 05:41:45|     null|NO_PROBLEM|         null|2017-05-11|\n",
      "|  372|      1|   1891|      6136658|-25.413174854615896| -49.20397031134223|              326.247|  CC170|      null|      null|      null|                null| 05:41:47|    30760|   BETWEEN|            0|2017-05-11|\n",
      "|  372|      1|   1891|      6136659|-25.412986287055883| -49.20349037546305|              378.858|  CC170|      null|-25.413058| -49.20353|            8.912048| 05:41:52|     null|NO_PROBLEM|         null|2017-05-11|\n",
      "|  372|      1|   1891|      6136660|-25.413358262455215| -49.20330982653354|              423.891|  CC170|      null|-25.413443|-49.203253|           11.016149| 05:42:00|     null|NO_PROBLEM|         null|2017-05-11|\n",
      "|  372|      1|   1891|      6136661| -25.41368178438006| -49.20315744079858|              462.872|  CC170|      null|      null|      null|                null| 05:42:03|     null|   BETWEEN|         null|2017-05-11|\n",
      "|  372|      1|   1891|      6136662| -25.41401802524562|  -49.2029929851231|               503.63|  CC170|      null|      null|      null|                null| 05:42:08|     null|   BETWEEN|         null|2017-05-11|\n",
      "|  372|      1|   1891|      6136663|  -25.4143918170944| -49.20281243619365|              548.847|  CC170|      null|      null|      null|                null| 05:42:12|     null|   BETWEEN|         null|2017-05-11|\n",
      "|  372|      1|   1891|      6136664| -25.41477143255683|-49.202639060271736|              594.375|  CC170|      null|      null|      null|                null| 05:42:17|     null|   BETWEEN|         null|2017-05-11|\n",
      "|  372|      1|   1891|      6136665| -25.41508018578273|-49.202495188649095|              631.515|  CC170|      null| -25.41504|-49.202528|            5.552165| 05:42:21|     null|NO_PROBLEM|         null|2017-05-11|\n",
      "|  372|      1|   1891|      6136666|-25.415409531428054| -49.20234192929479|              671.124|  CC170|      null|      null|      null|                null| 05:42:23|     null|   BETWEEN|         null|2017-05-11|\n",
      "|  372|      1|   1891|      6136667| -25.41558601453961| -49.20226127630417|              692.292|  CC170|      null|-25.415533|-49.202298|            6.953693| 05:42:25|     null|NO_PROBLEM|         null|2017-05-11|\n",
      "+-----+-------+-------+-------------+-------------------+-------------------+---------------------+-------+----------+----------+----------+--------------------+---------+---------+----------+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/local/tarciso/data/sample-data/ticketing-sample/doc1-2017051115.txt'\n",
    "ticketing_data = sqlContext.read.json(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|      DATAUTILIZACAO|\n",
      "+--------------------+\n",
      "|10/05/17 20:15:16...|\n",
      "|10/05/17 13:10:24...|\n",
      "|10/05/17 08:23:45...|\n",
      "|10/05/17 11:54:19...|\n",
      "|10/05/17 13:30:10...|\n",
      "|10/05/17 07:52:52...|\n",
      "|10/05/17 18:34:06...|\n",
      "|10/05/17 06:15:31...|\n",
      "|10/05/17 17:57:28...|\n",
      "|10/05/17 10:03:56...|\n",
      "|10/05/17 13:35:56...|\n",
      "|10/05/17 07:50:18...|\n",
      "|10/05/17 12:26:01...|\n",
      "|10/05/17 14:34:27...|\n",
      "|10/05/17 14:34:30...|\n",
      "|10/05/17 14:34:32...|\n",
      "|10/05/17 14:02:43...|\n",
      "|10/05/17 11:04:25...|\n",
      "|10/05/17 06:44:08...|\n",
      "|10/05/17 17:38:18...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ticketing_data.select(\"DATAUTILIZACAO\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_fmt = \"HH:mm:ss\"\n",
    "parse_time = unix_timestamp(\"timestamp\", time_fmt)\n",
    "trips_data = trips_data.withColumn(\"timestamp\", parse_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|timestamp|\n",
      "+---------+\n",
      "|    54823|\n",
      "|    56714|\n",
      "|    31274|\n",
      "|    31276|\n",
      "|    31280|\n",
      "|    31287|\n",
      "|    31291|\n",
      "|    31293|\n",
      "|    31297|\n",
      "|    31305|\n",
      "|    31307|\n",
      "|    31312|\n",
      "|    31320|\n",
      "|    31323|\n",
      "|    31328|\n",
      "|    31332|\n",
      "|    31337|\n",
      "|    31341|\n",
      "|    31343|\n",
      "|    31345|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips_data.select(\"timestamp\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_fmt = \"DD/MM/YY HH:mm:ss\"\n",
    "parse_datetime = unix_timestamp(\"DATAUTILIZACAO\", time_fmt)\n",
    "ticketing_data = ticketing_data.withColumn(\"DATAUTILIZACAO\", regexp_replace(col(\"DATAUTILIZACAO\"), \",000000\", \"\"))\n",
    "ticketing_data = ticketing_data.withColumn(\"DATAUTILIZACAO\", parse_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|DATAUTILIZACAO|\n",
      "+--------------+\n",
      "|    1483312516|\n",
      "|    1483287024|\n",
      "|    1483269825|\n",
      "|    1483282459|\n",
      "|    1483288210|\n",
      "|    1483267972|\n",
      "|    1483306446|\n",
      "|    1483262131|\n",
      "|    1483304248|\n",
      "|    1483275836|\n",
      "|    1483288556|\n",
      "|    1483267818|\n",
      "|    1483284361|\n",
      "|    1483292067|\n",
      "|    1483292070|\n",
      "|    1483292072|\n",
      "|    1483290163|\n",
      "|    1483279465|\n",
      "|    1483263848|\n",
      "|    1483303098|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ticketing_data.select(\"DATAUTILIZACAO\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute '_get_object_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-aeae6e5f0ed6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#ticketing_data = ticketing_data.withColumn(\"DATAUTILIZACAO\",(60*hour(col(\"DATAUTILIZACAO\")) +\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#                                                             minute(col(\"DATAUTILIZACAO\")))/5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mhour\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticketing_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DATAUTILIZACAO\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/local/tarciso/programs/spark-2.1.0-bin-hadoop2.7/python/pyspark/sql/functions.pyc\u001b[0m in \u001b[0;36mhour\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m    866\u001b[0m     \"\"\"\n\u001b[1;32m    867\u001b[0m     \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhour\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_java_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/tarciso/programs/spark-2.1.0-bin-hadoop2.7/python/pyspark/sql/column.pyc\u001b[0m in \u001b[0;36m_to_java_column\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mjcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mjcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_column_from_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mjcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/tarciso/programs/spark-2.1.0-bin-hadoop2.7/python/pyspark/sql/column.pyc\u001b[0m in \u001b[0;36m_create_column_from_name\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_create_column_from_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/tarciso/programs/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         \u001b[0margs_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m         \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCALL_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/tarciso/programs/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_build_args\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         args_command = \"\".join(\n\u001b[0;32m-> 1094\u001b[0;31m             [get_command_part(arg, self.pool) for arg in new_args])\n\u001b[0m\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/tarciso/programs/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_command_part\u001b[0;34m(parameter, python_proxy_pool)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mcommand_part\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\";\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minterface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mcommand_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mcommand_part\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/tarciso/programs/spark-2.1.0-bin-hadoop2.7/python/pyspark/sql/dataframe.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             raise AttributeError(\n\u001b[0;32m--> 964\u001b[0;31m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[1;32m    965\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute '_get_object_id'"
     ]
    }
   ],
   "source": [
    "def get_group_N_min(timestamp,N):\n",
    "    mins_since_midnight = 60*hour(timestamp) + minute(timestamp)\n",
    "    return(floor(mins_since_midnight/N))\n",
    "\n",
    "#ticketing_data = ticketing_data.withColumn(\"DATAUTILIZACAO\",(60*hour(col(\"DATAUTILIZACAO\")) + \n",
    "#                                                             minute(col(\"DATAUTILIZACAO\")))/5)\n",
    "#hour(ticketing_data.select(\"DATAUTILIZACAO\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
